{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407e49cd-c739-44ef-b595-5f3f67442270",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88e6b50-6928-4460-9097-f1ba29d86ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'C:/Users/3544bg/OneDrive - BP/Dissertation/'\n",
    "node_name = 'DK1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33778ed8-6fd0-4a9f-9106-1c383df21dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Check if pandas is installed, and install it if it is not\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    install(\"pandas\")\n",
    "    import pandas as pd\n",
    "    \n",
    "# Continue with the rest of your script after this\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a7b30-949b-41c9-b9de-4d4038a9caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_datetimes(base_path, node_name):\n",
    "    # Create the filepath\n",
    "    filepath = os.path.join(base_path, 'DayAheadPrice', node_name, 'Concatted', 'ConcattedPrices.tsv')\n",
    "    output_dir = os.path.join(base_path, 'DayAheadPrice', node_name, 'Reformatted')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, 'ReformattedPrices.tsv')\n",
    "    \n",
    "    # Load the TSV file into a DataFrame\n",
    "    df = pd.read_csv(filepath, sep='\\t')\n",
    "    \n",
    "    # Check if the MTU column exists\n",
    "    if 'MTU (CET/CEST)' not in df.columns:\n",
    "        raise ValueError(\"Expected column 'MTU (CET/CEST)' not found in the file.\")\n",
    "    \n",
    "    # Split the 'MTU (CET/CEST)' column into two new columns\n",
    "    df[['start_datetime', 'end_datetime']] = df['MTU (CET/CEST)'].str.split(' - ', expand=True)\n",
    "    \n",
    "    # Optionally convert the datetime strings to datetime objects\n",
    "    df['start_datetime'] = pd.to_datetime(df['start_datetime'], dayfirst=True)\n",
    "    df['end_datetime'] = pd.to_datetime(df['end_datetime'], dayfirst=True)\n",
    "    \n",
    "    # Extract hour of the day from start_datetime\n",
    "    df['HourOfDay'] = df['start_datetime'].dt.hour\n",
    "    \n",
    "    # Save the reformatted data back to a TSV file\n",
    "    df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(f\"Data Formatted and written to {output_path}\")\n",
    "    \n",
    "def concat_price_data(base_path, node_name):\n",
    "    # Construct the target folder path\n",
    "    target_folder = os.path.join(base_path, 'DayAheadPrice', node_name, 'Raw')\n",
    "    \n",
    "    # List all files in the target folder\n",
    "    files = [os.path.join(target_folder, f) for f in os.listdir(target_folder) if f.endswith('.csv')]\n",
    "    \n",
    "    # Check if there are files to process\n",
    "    if not files:\n",
    "        raise ValueError(\"No CSV files found in the directory.\")\n",
    "    \n",
    "    # Read the first file to get the header\n",
    "    initial_df = pd.read_csv(files[0])\n",
    "    header = initial_df.columns.tolist()\n",
    "    \n",
    "    # List to hold all dataframes\n",
    "    dfs = [initial_df]\n",
    "    \n",
    "    # Read each file and verify the header\n",
    "    for file in files[1:]:\n",
    "        df = pd.read_csv(file)\n",
    "        if list(df.columns) != header:\n",
    "            raise ValueError(\"CSV file headers do not match.\")\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Concatenate all dataframes into one\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Path for the concatenated output\n",
    "    output_dir = os.path.join(base_path, 'DayAheadPrice', node_name,'Concatted')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, 'ConcattedPrices.tsv')\n",
    "    \n",
    "    # Write the dataframe to a TSV file\n",
    "    final_df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(f\"Data concatenated and written to {output_path}\")\n",
    "\n",
    "\n",
    "def convert_to_hourly_array(base_path, node_name):\n",
    "    # Create the filepath for input and output\n",
    "    input_path = os.path.join(base_path, 'DayAheadPrice', node_name, 'Reformatted', 'ReformattedPrices.tsv')\n",
    "    output_dir = os.path.join(base_path, 'DayAheadPrice', node_name, 'Array')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, 'PriceArray.tsv')\n",
    "    \n",
    "    # Load the TSV file into a DataFrame\n",
    "    df = pd.read_csv(input_path, sep='\\t')\n",
    "    \n",
    "    # Convert start_datetime from string to datetime if not already\n",
    "    if df['start_datetime'].dtype == 'object':\n",
    "        df['start_datetime'] = pd.to_datetime(df['start_datetime'], dayfirst=True,format='ISO8601')\n",
    "    \n",
    "    # Pivot the DataFrame to get dates as rows and hours as columns\n",
    "    df['date'] = df['start_datetime'].dt.date  # Extract the date from start_datetime\n",
    "    df_pivot = df.pivot_table(index='date', columns='HourOfDay', values='Day-ahead Price [EUR/MWh]', aggfunc='mean')\n",
    "    \n",
    "    # Reset index to turn the date index back to a column\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "    \n",
    "    # Save the transformed DataFrame to a TSV file\n",
    "    df_pivot.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(f\"Hourly price array saved to {output_path}\")\n",
    "\n",
    "def add_averages_and_rolling(base_path, node_name):\n",
    "    # Define paths for input and output\n",
    "    input_path = os.path.join(base_path, 'DayAheadPrice', node_name, 'Array', 'PriceArray.tsv')\n",
    "    output_path = os.path.join(base_path, 'DayAheadPrice', node_name, 'Array', 'PriceArrayAverages.tsv')\n",
    "    \n",
    "    # Load the DataFrame\n",
    "    df = pd.read_csv(input_path, sep='\\t')\n",
    "    \n",
    "    # Calculate the daily average price across all hour columns\n",
    "    hour_columns = [col for col in df.columns if col.startswith('0') or col.isdigit()]  # Adapt if column naming differs\n",
    "    df['Daily_Average_Price'] = df[hour_columns].mean(axis=1)\n",
    "    \n",
    "    # Calculate the seven-day rolling average of the daily average price\n",
    "    df['Seven_Day_Rolling_Avg'] = df['Daily_Average_Price'].rolling(window=7, min_periods=1, center=True).mean()\n",
    "    \n",
    "    # Save the updated DataFrame\n",
    "    df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(f\"Updated data saved to {output_path}\")\n",
    "\n",
    "def concat_system_gen_files(base_path, node_name):\n",
    "    # Define the directory paths\n",
    "    raw_dir = os.path.join(base_path, 'SystemGeneration', node_name, 'Raw')\n",
    "    concatted_dir = os.path.join(base_path, 'SystemGeneration', node_name, 'Concatted')\n",
    "    \n",
    "    # Create the 'Concatted' directory if it doesn't exist\n",
    "    os.makedirs(concatted_dir, exist_ok=True)\n",
    "    \n",
    "    # Get a list of all CSV files in the 'Raw' directory\n",
    "    csv_files = [f for f in os.listdir(raw_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    # List to store all dataframes\n",
    "    all_dfs = []\n",
    "    common_header = None\n",
    "    \n",
    "    # Process each CSV file\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(raw_dir, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check if the header matches\n",
    "        header = tuple(df.columns)\n",
    "        if common_header is None:\n",
    "            common_header = header\n",
    "        elif common_header != header:\n",
    "            print(f\"Header mismatch in file: {file}\")\n",
    "            continue\n",
    "        \n",
    "        # Append dataframe to the list\n",
    "        all_dfs.append(df)\n",
    "    \n",
    "    # Concatenate all dataframes\n",
    "    if all_dfs:\n",
    "        concatenated_df = pd.concat(all_dfs, ignore_index=True)\n",
    "        \n",
    "        # Save the concatenated dataframe as a TSV file\n",
    "        output_filename = \"concatted_system_generation.tsv\"\n",
    "        output_path = os.path.join(concatted_dir, output_filename)\n",
    "        \n",
    "        concatenated_df.to_csv(output_path, index=False, sep='\\t')\n",
    "        \n",
    "        print(f\"Concatenation complete. File saved as {output_path}\")\n",
    "    else:\n",
    "        print(\"No matching headers found or no files to concatenate.\")\n",
    "\n",
    "def load_and_split_datetimes_SysGen(base_path, node_name):\n",
    "    # Create the filepath\n",
    "    filepath = os.path.join(base_path, 'SystemGeneration', node_name, 'Concatted', 'Concatted_System_Generation.tsv')\n",
    "    output_dir = os.path.join(base_path, 'SystemGeneration', node_name, 'Reformatted')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, 'ReformattedGeneration.tsv')\n",
    "    \n",
    "    # Load the TSV file into a DataFrame\n",
    "    df = pd.read_csv(filepath, sep='\\t')\n",
    "    \n",
    "    # Check if the MTU column exists\n",
    "    if 'MTU (CET/CEST)' not in df.columns:\n",
    "        raise ValueError(\"Expected column 'MTU (CET/CEST)' not found in the file.\")\n",
    "    \n",
    "    # Split the 'MTU (CET/CEST)' column into two new columns\n",
    "    df[['start_datetime', 'end_datetime']] = df['MTU (CET/CEST)'].str.split(' - ', expand=True)\n",
    "    \n",
    "    # Optionally convert the datetime strings to datetime objects\n",
    "    df['start_datetime'] = pd.to_datetime(df['start_datetime'], dayfirst=True)\n",
    "    df['end_datetime'] = pd.to_datetime(df['end_datetime'], dayfirst=True)\n",
    "    \n",
    "    # Extract hour of the day from start_datetime\n",
    "    df['HourOfDay'] = df['start_datetime'].dt.hour\n",
    "    \n",
    "    # Save the reformatted data back to a TSV file\n",
    "    df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(f\"Data formatted and written to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72798e12-1134-46b7-9bc7-3d0a4c72d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sysgen_to_hourly_array(base_path, node_name):\n",
    "    # Create the filepath for input and output\n",
    "    input_path = os.path.join(base_path, 'SystemGeneration', node_name, 'Reformatted', 'ReformattedGeneration.tsv')\n",
    "    output_dir = os.path.join(base_path, 'SystemGeneration', node_name, 'Array')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the TSV file into a DataFrame\n",
    "    df = pd.read_csv(input_path, sep='\\t')\n",
    "    \n",
    "    # Convert start_datetime from string to datetime if not already\n",
    "    if df['start_datetime'].dtype == 'object':\n",
    "        df['start_datetime'] = pd.to_datetime(df['start_datetime'], dayfirst=True,format='ISO8601')\n",
    "    \n",
    "    # Extract the date from start_datetime\n",
    "    df['date'] = df['start_datetime'].dt.date\n",
    "    \n",
    "    # Define the types and categories\n",
    "    types = ['Solar', 'Wind Onshore', 'Wind Offshore']\n",
    "    categories = ['Day Ahead', 'Intraday ', 'Current ']\n",
    "    \n",
    "    # Iterate over types and categories to create separate TSV files\n",
    "    for t in types:\n",
    "        for c in categories:\n",
    "            # Create the column name to pivot\n",
    "            column_name = f'Generation - {t}  [MW] {c}/ BZN|{node_name}'\n",
    "            \n",
    "            if column_name in df.columns:\n",
    "                # Pivot the DataFrame to get dates as rows and hours as columns\n",
    "                df_pivot = df.pivot_table(index='date', columns='HourOfDay', values=column_name, aggfunc='mean')\n",
    "                \n",
    "                # Reset index to turn the date index back to a column\n",
    "                df_pivot.reset_index(inplace=True)\n",
    "                \n",
    "                # Create the output filename\n",
    "                output_filename = f'{t.replace(\" \", \"_\")}_{c.replace(\" \", \"_\")}_Array.tsv'\n",
    "                output_path = os.path.join(output_dir, output_filename)\n",
    "                \n",
    "                # Save the transformed DataFrame to a TSV file\n",
    "                df_pivot.to_csv(output_path, sep='\\t', index=False)\n",
    "                print(f\"Hourly array saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8588a70-9b6b-4164-aef9-8ce10485828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data concatenated and written to C:/Users/3544bg/OneDrive - BP/Dissertation/DayAheadPrice\\DK1\\Concatted\\ConcattedPrices.tsv\n",
      "Data Formatted and written to C:/Users/3544bg/OneDrive - BP/Dissertation/DayAheadPrice\\DK1\\Reformatted\\ReformattedPrices.tsv\n",
      "Hourly price array saved to C:/Users/3544bg/OneDrive - BP/Dissertation/DayAheadPrice\\DK1\\Array\\PriceArray.tsv\n",
      "Updated data saved to C:/Users/3544bg/OneDrive - BP/Dissertation/DayAheadPrice\\DK1\\Array\\PriceArrayAverages.tsv\n"
     ]
    }
   ],
   "source": [
    "concat_price_data(base_path,node_name)\n",
    "load_and_split_datetimes(base_path,node_name)\n",
    "convert_to_hourly_array(base_path, node_name)\n",
    "add_averages_and_rolling(base_path, node_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aee71c86-c01e-4d2e-a42e-c6e0045e34d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation complete. File saved as C:/Users/3544bg/OneDrive - BP/Dissertation/SystemGeneration\\DK1\\Concatted\\concatted_system_generation.tsv\n",
      "Data formatted and written to C:/Users/3544bg/OneDrive - BP/Dissertation/SystemGeneration\\DK1\\Reformatted\\ReformattedGeneration.tsv\n",
      "Hourly array saved to C:/Users/3544bg/OneDrive - BP/Dissertation/SystemGeneration\\DK1\\Array\\Solar_Day_Ahead_Array.tsv\n",
      "Hourly array saved to C:/Users/3544bg/OneDrive - BP/Dissertation/SystemGeneration\\DK1\\Array\\Solar_Intraday__Array.tsv\n",
      "Hourly array saved to C:/Users/3544bg/OneDrive - BP/Dissertation/SystemGeneration\\DK1\\Array\\Solar_Current__Array.tsv\n",
      "Hourly array saved to C:/Users/3544bg/OneDrive - BP/Dissertation/SystemGeneration\\DK1\\Array\\Wind_Onshore_Day_Ahead_Array.tsv\n",
      "Hourly array saved to C:/Users/3544bg/OneDrive - BP/Dissertation/SystemGeneration\\DK1\\Array\\Wind_Onshore_Intraday__Array.tsv\n",
      "Hourly array saved to C:/Users/3544bg/OneDrive - BP/Dissertation/SystemGeneration\\DK1\\Array\\Wind_Onshore_Current__Array.tsv\n",
      "Hourly array saved to C:/Users/3544bg/OneDrive - BP/Dissertation/SystemGeneration\\DK1\\Array\\Wind_Offshore_Day_Ahead_Array.tsv\n",
      "Hourly array saved to C:/Users/3544bg/OneDrive - BP/Dissertation/SystemGeneration\\DK1\\Array\\Wind_Offshore_Intraday__Array.tsv\n",
      "Hourly array saved to C:/Users/3544bg/OneDrive - BP/Dissertation/SystemGeneration\\DK1\\Array\\Wind_Offshore_Current__Array.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "concat_system_gen_files(base_path, node_name)\n",
    "load_and_split_datetimes_SysGen(base_path, node_name)\n",
    "convert_sysgen_to_hourly_array(base_path, node_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a08a163-e0fa-457c-b292-0a5b31fb0287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
